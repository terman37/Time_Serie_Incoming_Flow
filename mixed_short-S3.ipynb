{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "t1 = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import boto3\n",
    "from zipfile import ZipFile\n",
    "\n",
    "import statsmodels as sm\n",
    "import pmdarima as pm\n",
    "from pmdarima.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the last file from S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Params\n",
    "bucket_name = 'machinelearning'\n",
    "path_to_files = 'projets/ml_ige_entrants/data/'\n",
    "zip_file = './data/data.zip'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config file for endpoint url in .aws folder\n",
    "import os\n",
    "config_file = '.custom_config'\n",
    "aws_path = os.path.join(os.environ['USERPROFILE'],'.aws',config_file)\n",
    "\n",
    "with open(aws_path,'r') as f:\n",
    "    lines = f.readlines()\n",
    "    \n",
    "endpoint = [i.split('=')[1].strip() for i in lines if i.startswith('endpoint_url')][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect\n",
    "session = boto3.session.Session()\n",
    "s3 = session.resource(\n",
    "    service_name='s3',\n",
    "    endpoint_url=endpoint,\n",
    ")\n",
    "\n",
    "# Get files in folder\n",
    "bucket = s3.Bucket(bucket_name)\n",
    "bucket_objects = bucket.objects.filter(Prefix=path_to_files)\n",
    "unsorted = []\n",
    "for obj in bucket_objects:\n",
    "    unsorted.append([obj.key,int(obj.last_modified.strftime(\"%S\"))])\n",
    "\n",
    "# sort and get the last one\n",
    "last_file = sorted(unsorted, key=lambda l:l[1], reverse=True)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download zip\n",
    "MyObject = s3.Object(bucket_name,last_file)\n",
    "MyObject.download_file(zip_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract zip\n",
    "with ZipFile(zip_file, 'r') as zf:\n",
    "    zf.extractall('./data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Needs to add error managemet in case file not existing...\n",
    "# Add replacement of old files...\n",
    "# Also add cleanup of temp files (zip)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = './data/ml_ige_entrants_ds1.csv'\n",
    "\n",
    "myfilters = {'SITE':'VELIZY','FLUX_ACTIVITE':'FLUX PRESTATION','SERVICE_ACTIVITE':'PRESTATION'}\n",
    "# exogs = ['MEDIA']\n",
    "exogs = []\n",
    "\n",
    "testsize = .05\n",
    "\n",
    "scale='W' # 'B','W','SM'\n",
    "periods = 4\n",
    "\n",
    "weighted_total = True\n",
    "\n",
    "max_date='2020-06-29'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time df = pd.read_csv(filename,sep=';',engine='python',decimal=',') #,index_col='DATEDATA',parse_dates=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df.apply(lambda x: x.str.strip() if x.dtype == \"object\" else x)\n",
    "# df = df.apply(lambda x: x.str.upper() if x.dtype == \"object\" else x)\n",
    "\n",
    "if weighted_total:\n",
    "    df['TOTAL'] = df.TOTAL * df.COEFF\n",
    "    \n",
    "df = df.drop(columns=['COEFF'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encode exog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encod_exogs(df, cols):\n",
    "    dfenc=[]\n",
    "    concatlist = [df]\n",
    "    for i,col in enumerate(cols):\n",
    "        exog_var = df[col].fillna('Unknown').to_numpy().reshape(-1,1)\n",
    "        encod_fit = LabelBinarizer().fit(exog_var)\n",
    "        encoded = encod_fit.transform(exog_var)\n",
    "        dfenc.append(pd.DataFrame(encoded,columns=encod_fit.classes_))\n",
    "        concatlist.append(dfenc[i])\n",
    "\n",
    "    dfnew = pd.concat(concatlist,axis=1)\n",
    "    return dfnew\n",
    "\n",
    "dfnew = encod_exogs(df,exogs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_df(df, mydict):\n",
    "    df_filter = df.copy()\n",
    "    for key,value in mydict.items():\n",
    "        df_filter = df_filter[df_filter[key]==value]\n",
    "    return df_filter\n",
    "    \n",
    "df_filter = filter_df(dfnew, myfilters)\n",
    "df_filter = df_filter[df_filter['DATEDATA']<=max_date]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filter.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Aggregated Df with DateTime Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df_filter.groupby('DATEDATA').sum()\n",
    "df2 = df2.asfreq(freq='B')\n",
    "df2['TOTAL'].fillna(0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    df2['ANO BATCH']=df2['ANO BATCH']+df2['ANOS BATCHS']\n",
    "    df2['EMAIL']=df2['EMAIL']+df2['COURRIEL']\n",
    "    df2 = df2[df2.index>='2018-08-01'].drop(columns=['ANOS BATCHS','COURRIEL'])\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2=df2.resample(scale).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split in train test to compare with predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train,test = train_test_split(df2, test_size=testsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_endog = train['TOTAL']\n",
    "train_exog = train.drop(columns=['TOTAL'])\n",
    "\n",
    "test_endog = test['TOTAL']\n",
    "test_exog = test.drop(columns=['TOTAL'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_exog.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pm.tsdisplay(train_endog, lag_max=20, title=\"Sunspots\", show=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pmdarima import preprocessing\n",
    "\n",
    "# y_bc, l = preprocessing.BoxCoxEndogTransformer().fit_transform(train_endog)\n",
    "# pm.tsdisplay(y_bc, lag_max=20, title=\"Sunspots (BoxCox-transformed)\", show=True)\n",
    "# print(\"lambda %s\" % l)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model auto.arima"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(train_exog.columns) == 0:\n",
    "    modl = pm.auto_arima(train_endog, error_action='ignore', trace=True,\n",
    "                      suppress_warnings=True, maxiter=10,\n",
    "                      seasonal=True, m=periods)\n",
    "else:\n",
    "    modl = pm.auto_arima(train_endog,exogenous=train_exog, error_action='ignore', trace=True,\n",
    "                      suppress_warnings=True, maxiter=10,\n",
    "                      seasonal=True, m=periods)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(modl.order)\n",
    "print(modl.seasonal_order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = [10, 10]\n",
    "modl.plot_diagnostics();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds, conf_int = modl.predict(n_periods=test.shape[0],exogenous=test_exog, return_conf_int=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model HoltWinters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from statsmodels.tsa.holtwinters import ExponentialSmoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modl2 = ExponentialSmoothing(train_endog, trend='add', damped=False, seasonal='add', seasonal_periods=periods).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hwpreds = modl2.predict(start=test_endog.index[0], end=test_endog.index[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = pd.DataFrame(test_endog.copy())\n",
    "graph = graph.rename(columns={'TOTAL':'TEST'})\n",
    "graph['preds'] = preds\n",
    "# graph['hwpreds'] = hwpreds\n",
    "graph['lb'] = conf_int[:,0]\n",
    "graph['ub'] = conf_int[:,1]\n",
    "graph = graph.append(pd.DataFrame(train_endog))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphz = graph[graph.index>'2020-01-01']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = [15, 10]\n",
    "g1 = plt.plot(graphz.index, graphz.TOTAL, label='Train')\n",
    "g2 = plt.plot(graphz.index, graphz.TEST,'c--', label='Test')\n",
    "g3 = plt.plot(graphz.index, graphz.preds,'r', label='Pred',linewidth=2, alpha=.5)\n",
    "# g3b = plt.plot(graphz.index, graphz.hwpreds,'g', label='Pred',linewidth=2)\n",
    "g4 = plt.fill_between(graphz.index,graphz.lb,graphz.ub,color='r',alpha=.2, label='C.I.')\n",
    "plt.legend(loc='upper left')\n",
    "plt.title('Actual test samples vs. forecasts')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t2 = time.time()\n",
    "\n",
    "print('Total Run time: %i secs' % (t2-t1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "time-serie",
   "language": "python",
   "name": "time-serie"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
