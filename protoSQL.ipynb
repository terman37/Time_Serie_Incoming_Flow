{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "t1 = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "from datetime import date\n",
    "import pandas as pd\n",
    "import itertools\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from configparser import ConfigParser\n",
    "import pyodbc\n",
    "\n",
    "# import statsmodels as sm\n",
    "import pmdarima as pm\n",
    "# from pmdarima.model_selection import train_test_split\n",
    "# from sklearn.preprocessing import LabelBinarizer\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths & Files\n",
    "db_conf_path = os.path.join(os.environ['USERPROFILE'],'db_connection.conf')\n",
    "\n",
    "# ML Settings\n",
    "# testsize = .05\n",
    "scale='B'                # Check if needed or hardcoded\n",
    "periods = 5              # Check if needed or hardcoded\n",
    "weighted_total = False\n",
    "prediction_length = 5\n",
    "\n",
    "# Data Settings\n",
    "myfilters = {'SITE':['VELIZY'],\n",
    "             'SERVICE_ACTIVITE':['PRESTATION','CONTRAT - COTISATION']}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DB Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def db_connection(db_conf):\n",
    "    config = ConfigParser()\n",
    "    config.read(db_conf_path)\n",
    "\n",
    "    srv_name = config['CONNECTION']['srv_name']\n",
    "    db_name = config['CONNECTION']['db_name']\n",
    "    drv = config['CONNECTION']['drv']\n",
    "    usr = config['CONNECTION']['usr']\n",
    "    pwd = config['CONNECTION']['pwd']\n",
    "\n",
    "    conn_str = 'DRIVER=%s; SERVER=%s;DATABASE=%s;UID=%s;PWD=%s' % (drv, srv_name, db_name, usr, pwd)\n",
    "    cnxn = pyodbc.connect(conn_str)\n",
    "    return cnxn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get Datas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_datas(strsql):\n",
    "    with db_connection(db_conf_path) as conn:\n",
    "        result = pd.read_sql(sqlstr, conn)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocess columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_df(df,weighted):\n",
    "    if weighted:\n",
    "        df['TOTAL'] = df.TOTAL * df.COEFF\n",
    "    df = df.drop(columns=['COEFF'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Aggregated Df with DateTime Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_df(df):\n",
    "    df2 = df.groupby('DATEDATA').sum()\n",
    "    df2 = df2.asfreq(freq='B')\n",
    "    df2['TOTAL'].fillna(0,inplace=True)\n",
    "    df2=df2.resample(scale).sum()\n",
    "    return df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main Loop Iterate over filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate loops variants\n",
    "myfilters = {'SITE':['VELIZY',],\n",
    "             'SERVICE_ACTIVITE':['PRESTATION','CONTRAT - COTISATION']}\n",
    "\n",
    "v_keys = list(myfilters.keys())\n",
    "v = list(myfilters.values())\n",
    "\n",
    "liste = list(itertools.product(*v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strSQL_start = \"SELECT * FROM ML_IGE_ENTRANTS_DS1 \"\n",
    "\n",
    "for variant in liste:\n",
    "    print(variant)\n",
    "\n",
    "    # Generate SELECT query\n",
    "    strSQLW = \"WHERE \"\n",
    "    for i in range(len(variant)):\n",
    "        strSQLW += v_keys[i]\n",
    "        strSQLW += \"=\"\n",
    "        strSQLW += \"'\" + str(variant[i]) + \"'\"\n",
    "        strSQLW += ' AND '\n",
    "    strSQL = strSQL_start + strSQLW[:-5]\n",
    "    \n",
    "    # Get datas\n",
    "    df = get_datas(strSQL)\n",
    "    \n",
    "    # Prepare datas\n",
    "    df_pre = preprocess_df(df, weighted_total)\n",
    "    df_agg = aggregate_df(df_pre)\n",
    "    \n",
    "    # ARIMA Modeling\n",
    "    model = pm.auto_arima(df_agg, error_action='ignore', trace=False,\n",
    "                          suppress_warnings=True, maxiter=10,\n",
    "                          seasonal=True, m=periods)\n",
    "    preds, conf_int = model.predict(n_periods=prediction_length, return_conf_int=True)\n",
    "    \n",
    "    # Create Prediction dataframe to write in DB\n",
    "    idx=[]\n",
    "    for i in range(1,prediction_length+1):\n",
    "        nd = df_agg.index[-1]+pd.tseries.offsets.BDay(i)\n",
    "        idx.append(nd)\n",
    "    t=pd.DataFrame(np.concatenate((preds.reshape(-1,1),conf_int),axis=1),columns=['PRED','LB','UB'],index=idx)\n",
    "\n",
    "    for i in range(len(variant)):\n",
    "        t[v_keys[i]]=variant[i]\n",
    "    \n",
    "    t['WEIGHTED']=weighted_total\n",
    "    today = date.today()\n",
    "    d = today.strftime(\"%Y-%m-%d\")\n",
    "    t['PREDDATE']=d\n",
    "    \n",
    "    \n",
    "    # Create DELETE SQL string\n",
    "    strSQL = \"DELETE * FROM ML_IGE_ENTRANTS_PRED WHERE DATEPRED=\\'\" + d + \"\\'\"\n",
    "\n",
    "    # with db_connection(db_conf_path) as conn:\n",
    "    #     conn.execute(strSQL)\n",
    "    #     conn.commit()\n",
    "    \n",
    "    \n",
    "    # Create INSERT SQL string\n",
    "    strSQL = \"INSERT INTO ML_IGE_ENTRANTS_PRED (DATEDATA,PRED,LB,UB,SITE,SERVICE_ACTIVITE,WEIGHTED,DATEPRED) VALUES \"\n",
    "    values=\"\"\n",
    "    for idx, row in t.iterrows():\n",
    "        values += \"(\"\n",
    "        values += \"\\'\" + idx.strftime('%Y-%m-%d') + \"\\',\"\n",
    "        values += str(int(row.PRED)) + ','\n",
    "        values += str(int(row.LB)) + ','\n",
    "        values += str(int(row.UB)) + ','\n",
    "        values += row.SITE + ','\n",
    "        values += row.SERVICE_ACTIVITE + ','\n",
    "        values += str(int(row.WEIGHTED)) + ','\n",
    "        values += \"\\'\" + row.PREDDATE + \"\\'\"\n",
    "        values+='),'\n",
    "\n",
    "    strSQL += values\n",
    "    strSQL = strSQL[:-1]\n",
    "\n",
    "    # with db_connection(db_conf_path) as conn:\n",
    "    #     conn.execute(strSQL)\n",
    "    #     conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt = t.reset_index(level=0)\n",
    "tt.rename(columns={'index':'DATEDATA'},inplace=True)\n",
    "tt['DATEDATA'] = [x.strftime('%Y-%m-%d') for x in tt['DATEDATA']]\n",
    "print(tuple(list(tt.columns)))\n",
    "str(tuple(list(tt.iloc[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx,row in tt.iterrows():\n",
    "    print(tuple((row)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = get_datas(sqlstr)\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pre = preprocess_df(df, weighted_total)\n",
    "# df_pre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_agg = aggregate_df(df_pre)\n",
    "# df_agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = pm.auto_arima(df_agg, error_action='ignore', trace=False,\n",
    "                      suppress_warnings=True, maxiter=10,\n",
    "                      seasonal=True, m=periods)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(model.order)\n",
    "# print(model.seasonal_order)\n",
    "# plt.rcParams['figure.figsize'] = [10, 10]\n",
    "# model.plot_diagnostics();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds, conf_int = model.predict(n_periods=prediction_length, return_conf_int=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Prediction dataframe to write in DB\n",
    "idx=[]\n",
    "for i in range(1,prediction_length+1):\n",
    "    nd = df_agg.index[-1]+pd.tseries.offsets.BDay(i)\n",
    "    idx.append(nd)\n",
    "t=pd.DataFrame(np.concatenate((preds.reshape(-1,1),conf_int),axis=1),columns=['PRED','LB','UB'],index=idx)\n",
    "\n",
    "t['SITE']='VELIZY'                       # PARAMETER\n",
    "t['SERVICE_ACTIVITE']='PRESTATION'       # PARAMETER\n",
    "t['WEIGHTED']=weighted_total\n",
    "\n",
    "today = date.today()\n",
    "d = today.strftime(\"%Y-%m-%d\")\n",
    "t['PREDDATE']=d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_agg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete predictions if existing\n",
    "strSQL = \"DELETE * FROM ML_IGE_ENTRANTS_PRED WHERE DATEPRED=\\'\" + d + \"\\'\"\n",
    "\n",
    "# with db_connection(db_conf_path) as conn:\n",
    "#     conn.execute(strSQL)\n",
    "#     conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strSQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create INSERT SQL string\n",
    "\n",
    "strSQL = \"INSERT INTO ML_IGE_ENTRANTS_PRED (DATEDATA,PRED,LB,UB,SITE,SERVICE_ACTIVITE,WEIGHTED,DATEPRED) VALUES \"\n",
    "values=\"\"\n",
    "for idx, row in t.iterrows():\n",
    "    values += \"(\"\n",
    "    values += \"\\'\" + idx.strftime('%Y-%m-%d') + \"\\',\"\n",
    "    values += str(int(row.PRED)) + ','\n",
    "    values += str(int(row.LB)) + ','\n",
    "    values += str(int(row.UB)) + ','\n",
    "    values += row.SITE + ','\n",
    "    values += row.SERVICE_ACTIVITE + ','\n",
    "    values += str(int(row.WEIGHTED)) + ','\n",
    "    values += \"\\'\" + row.PREDDATE + \"\\'\"\n",
    "    values+='),'\n",
    "\n",
    "strSQL += values\n",
    "strSQL = strSQL[:-1]\n",
    "\n",
    "# with db_connection(db_conf_path) as conn:\n",
    "#     conn.execute(strSQL)\n",
    "#     conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strSQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = pd.DataFrame(test_endog.copy())\n",
    "graph = graph.rename(columns={'TOTAL':'TEST'})\n",
    "graph['preds'] = preds\n",
    "# graph['hwpreds'] = hwpreds\n",
    "graph['lb'] = conf_int[:,0]\n",
    "graph['ub'] = conf_int[:,1]\n",
    "graph = graph.append(pd.DataFrame(train_endog))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphz = graph[graph.index>'2020-01-01']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = [15, 10]\n",
    "g1 = plt.plot(graphz.index, graphz.TOTAL, label='Train')\n",
    "g2 = plt.plot(graphz.index, graphz.TEST,'c--', label='Test')\n",
    "g3 = plt.plot(graphz.index, graphz.preds,'r', label='Pred',linewidth=2, alpha=.5)\n",
    "# g3b = plt.plot(graphz.index, graphz.hwpreds,'g', label='Pred',linewidth=2)\n",
    "g4 = plt.fill_between(graphz.index,graphz.lb,graphz.ub,color='r',alpha=.1, label='C.I.')\n",
    "plt.legend(loc='upper left')\n",
    "plt.title('Actual test samples vs. forecasts')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t2 = time.time()\n",
    "\n",
    "print('Total Run time: %i secs' % (t2-t1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "time-serie",
   "language": "python",
   "name": "time-serie"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
